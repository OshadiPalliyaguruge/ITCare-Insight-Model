{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure to  use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:26.954639Z",
     "iopub.status.busy": "2025-03-12T20:28:26.954297Z",
     "iopub.status.idle": "2025-03-12T20:28:27.167679Z",
     "shell.execute_reply": "2025-03-12T20:28:27.166572Z",
     "shell.execute_reply.started": "2025-03-12T20:28:26.954605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 12 20:28:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:39.549609Z",
     "iopub.status.busy": "2025-03-12T20:28:39.549275Z",
     "iopub.status.idle": "2025-03-12T20:28:39.554115Z",
     "shell.execute_reply": "2025-03-12T20:28:39.553172Z",
     "shell.execute_reply.started": "2025-03-12T20:28:39.549584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:41.684289Z",
     "iopub.status.busy": "2025-03-12T20:28:41.683976Z",
     "iopub.status.idle": "2025-03-12T20:28:41.689766Z",
     "shell.execute_reply": "2025-03-12T20:28:41.688795Z",
     "shell.execute_reply.started": "2025-03-12T20:28:41.684264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import joblib\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:45.490548Z",
     "iopub.status.busy": "2025-03-12T20:28:45.490200Z",
     "iopub.status.idle": "2025-03-12T20:28:45.494475Z",
     "shell.execute_reply": "2025-03-12T20:28:45.493375Z",
     "shell.execute_reply.started": "2025-03-12T20:28:45.490523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:47.958905Z",
     "iopub.status.busy": "2025-03-12T20:28:47.958577Z",
     "iopub.status.idle": "2025-03-12T20:28:48.661784Z",
     "shell.execute_reply": "2025-03-12T20:28:48.661052Z",
     "shell.execute_reply.started": "2025-03-12T20:28:47.958880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset (Make sure the dataset is uploaded to Kaggle's environment)\n",
    "data = pd.read_csv('/kaggle/input/itcarenew/incident_report_preprocessed_final_98000_cleaned.csv')  # Replace with actual dataset path\n",
    "\n",
    "# Prepare input and output\n",
    "X = data[['Operational Categorization Tier 1', 'Summary', 'Priority', 'Organization', 'Department']]\n",
    "y = data['Assigned Group']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[['Operational Categorization Tier 1', 'Priority', 'Organization', 'Department']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:51.310056Z",
     "iopub.status.busy": "2025-03-12T20:28:51.309637Z",
     "iopub.status.idle": "2025-03-12T20:28:51.314803Z",
     "shell.execute_reply": "2025-03-12T20:28:51.313762Z",
     "shell.execute_reply.started": "2025-03-12T20:28:51.310022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an output folder in Kaggle to save models and results\n",
    "output_dir = f\"/kaggle/working/output_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T20:28:56.186104Z",
     "iopub.status.busy": "2025-03-12T20:28:56.185805Z",
     "iopub.status.idle": "2025-03-12T21:41:23.373935Z",
     "shell.execute_reply": "2025-03-12T21:41:23.372931Z",
     "shell.execute_reply.started": "2025-03-12T20:28:56.186083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(texts, tokenizer, bert_model):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        outputs = bert_model(**inputs)\n",
    "        # Get the mean of the last hidden state\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Get BERT embeddings for the text features\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "summary_embeddings = get_bert_embeddings(X['Summary'].tolist(), tokenizer, bert_model)\n",
    "\n",
    "# Save BERT embeddings\n",
    "np.save(f'{output_dir}/bert_embeddings.npy', summary_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load BERT Embeddings for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T21:52:12.746146Z",
     "iopub.status.busy": "2025-03-12T21:52:12.745825Z",
     "iopub.status.idle": "2025-03-12T21:52:13.103498Z",
     "shell.execute_reply": "2025-03-12T21:52:13.102814Z",
     "shell.execute_reply.started": "2025-03-12T21:52:12.746120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load BERT embeddings\n",
    "summary_embeddings = np.load(f'{output_dir}/bert_embeddings.npy')\n",
    "\n",
    "# Combine the one-hot encoded features with BERT embeddings\n",
    "X_final = np.hstack((X_encoded, summary_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the Model to Use Precomputed BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T21:52:16.529153Z",
     "iopub.status.busy": "2025-03-12T21:52:16.528858Z",
     "iopub.status.idle": "2025-03-12T21:52:16.535507Z",
     "shell.execute_reply": "2025-03-12T21:52:16.534540Z",
     "shell.execute_reply.started": "2025-03-12T21:52:16.529132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetworkWithPrecomputedBERT(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetworkWithPrecomputedBERT, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, output_size)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through fully connected layers\n",
    "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T21:52:20.929918Z",
     "iopub.status.busy": "2025-03-12T21:52:20.929610Z",
     "iopub.status.idle": "2025-03-12T21:52:21.392078Z",
     "shell.execute_reply": "2025-03-12T21:52:21.391171Z",
     "shell.execute_reply.started": "2025-03-12T21:52:20.929894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Map y to numeric values and save the mapping\n",
    "y_encoded, y_mapping = pd.factorize(y)\n",
    "y_mapping_dict = dict(enumerate(y_mapping))  # Create mapping for y\n",
    "\n",
    "joblib.dump(y_mapping_dict, f'{output_dir}/advanced_new_y_mapping.pkl')  # Save y mapping\n",
    "\n",
    "# Save the mapping for X (One-Hot Encoded features)\n",
    "X_mapping_dict = {i: col for i, col in enumerate(encoder.get_feature_names_out())}  # Create mapping for X\n",
    "joblib.dump(X_mapping_dict, f'{output_dir}/advanced_new_X_mapping.pkl')  # Save X mapping\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_final, y_encoded, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save X_test and y_test to separate files for future use\n",
    "np.save(f'{output_dir}/advanced_X_test.npy', X_test)\n",
    "np.save(f'{output_dir}/advanced__test.npy', y_test)\n",
    "np.save(f'{output_dir}/advanced_X_val.npy', X_val)\n",
    "np.save(f'{output_dir}/advanced_y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T21:53:49.983237Z",
     "iopub.status.busy": "2025-03-12T21:53:49.982884Z",
     "iopub.status.idle": "2025-03-12T21:56:07.061019Z",
     "shell.execute_reply": "2025-03-12T21:56:07.060086Z",
     "shell.execute_reply.started": "2025-03-12T21:53:49.983210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.2139\n",
      "Validation Accuracy: 68.03%\n",
      "Epoch [2/100], Loss: 1.0454\n",
      "Validation Accuracy: 68.68%\n",
      "Epoch [3/100], Loss: 1.0126\n",
      "Validation Accuracy: 69.18%\n",
      "Epoch [4/100], Loss: 0.9949\n",
      "Validation Accuracy: 69.67%\n",
      "Epoch [5/100], Loss: 0.9828\n",
      "Validation Accuracy: 69.34%\n",
      "Epoch [6/100], Loss: 0.9683\n",
      "Validation Accuracy: 69.34%\n",
      "Epoch [7/100], Loss: 0.9602\n",
      "Validation Accuracy: 69.70%\n",
      "Epoch [8/100], Loss: 0.9512\n",
      "Validation Accuracy: 69.40%\n",
      "Epoch [9/100], Loss: 0.9448\n",
      "Validation Accuracy: 69.48%\n",
      "Epoch [10/100], Loss: 0.9362\n",
      "Validation Accuracy: 69.99%\n",
      "Epoch [11/100], Loss: 0.9302\n",
      "Validation Accuracy: 69.88%\n",
      "Epoch [12/100], Loss: 0.9232\n",
      "Validation Accuracy: 70.14%\n",
      "Epoch [13/100], Loss: 0.9209\n",
      "Validation Accuracy: 70.02%\n",
      "Epoch [14/100], Loss: 0.9152\n",
      "Validation Accuracy: 69.81%\n",
      "Epoch [15/100], Loss: 0.9110\n",
      "Validation Accuracy: 69.56%\n",
      "Epoch [16/100], Loss: 0.9071\n",
      "Validation Accuracy: 69.71%\n",
      "Epoch [17/100], Loss: 0.9008\n",
      "Validation Accuracy: 69.97%\n",
      "Epoch [18/100], Loss: 0.8980\n",
      "Validation Accuracy: 69.81%\n",
      "Epoch [19/100], Loss: 0.8956\n",
      "Validation Accuracy: 70.04%\n",
      "Epoch [20/100], Loss: 0.8928\n",
      "Validation Accuracy: 70.00%\n",
      "Epoch [21/100], Loss: 0.8898\n",
      "Validation Accuracy: 69.96%\n",
      "Epoch [22/100], Loss: 0.8848\n",
      "Validation Accuracy: 69.90%\n",
      "Early stopping due to no improvement in validation accuracy.\n",
      "Test Accuracy: 69.78%\n",
      "Model, encoder, and metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_final.shape[1]\n",
    "output_size = len(np.unique(y_encoded))\n",
    "model = NeuralNetworkWithPrecomputedBERT(input_size, output_size)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*100)\n",
    "\n",
    "# Training loop with Early Stopping\n",
    "epochs = 100\n",
    "best_val_accuracy = 0\n",
    "patience = 10  # Early stopping patience\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Validation metrics\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_accuracy = accuracy_score(y_val, val_predicted)\n",
    "        print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), f'{output_dir}/best_trained_model_{timestamp}.pth')\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping due to no improvement in validation accuracy.\")\n",
    "                break\n",
    "\n",
    "# Test metrics\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = accuracy_score(y_test, test_predicted)\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the encoder and metadata\n",
    "torch.save(model.state_dict(), f'{output_dir}/advanced_trained_model.pth')\n",
    "torch.save(model, f'{output_dir}/advanced_trained_model_2.pth')\n",
    "joblib.dump(encoder, f'{output_dir}/advanced_trained_encoder.pkl')\n",
    "joblib.dump({'input_size': input_size, 'output_size': output_size}, f'{output_dir}/advanced_metadata.pkl')\n",
    "print(\"Model, encoder, and metadata saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T22:03:42.775582Z",
     "iopub.status.busy": "2025-03-12T22:03:42.775186Z",
     "iopub.status.idle": "2025-03-12T22:14:16.221550Z",
     "shell.execute_reply": "2025-03-12T22:14:16.220650Z",
     "shell.execute_reply.started": "2025-03-12T22:03:42.775555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.2168\n",
      "Validation Accuracy: 67.98%\n",
      "Epoch [2/100], Loss: 1.0478\n",
      "Validation Accuracy: 68.40%\n",
      "Epoch [3/100], Loss: 1.0166\n",
      "Validation Accuracy: 68.63%\n",
      "Epoch [4/100], Loss: 0.9937\n",
      "Validation Accuracy: 68.98%\n",
      "Epoch [5/100], Loss: 0.9802\n",
      "Validation Accuracy: 69.12%\n",
      "Epoch [6/100], Loss: 0.9693\n",
      "Validation Accuracy: 69.86%\n",
      "Epoch [7/100], Loss: 0.9596\n",
      "Validation Accuracy: 69.58%\n",
      "Epoch [8/100], Loss: 0.9502\n",
      "Validation Accuracy: 69.50%\n",
      "Epoch [9/100], Loss: 0.9435\n",
      "Validation Accuracy: 69.37%\n",
      "Epoch [10/100], Loss: 0.9379\n",
      "Validation Accuracy: 69.78%\n",
      "Epoch [11/100], Loss: 0.9320\n",
      "Validation Accuracy: 69.16%\n",
      "Epoch [12/100], Loss: 0.9245\n",
      "Validation Accuracy: 69.80%\n",
      "Epoch [13/100], Loss: 0.9217\n",
      "Validation Accuracy: 69.88%\n",
      "Epoch [14/100], Loss: 0.9139\n",
      "Validation Accuracy: 69.89%\n",
      "Epoch [15/100], Loss: 0.9117\n",
      "Validation Accuracy: 69.73%\n",
      "Epoch [16/100], Loss: 0.9061\n",
      "Validation Accuracy: 70.12%\n",
      "Epoch [17/100], Loss: 0.9047\n",
      "Validation Accuracy: 70.02%\n",
      "Epoch [18/100], Loss: 0.8982\n",
      "Validation Accuracy: 69.88%\n",
      "Epoch [19/100], Loss: 0.8959\n",
      "Validation Accuracy: 69.98%\n",
      "Epoch [20/100], Loss: 0.8929\n",
      "Validation Accuracy: 70.16%\n",
      "Epoch [21/100], Loss: 0.8888\n",
      "Validation Accuracy: 70.03%\n",
      "Epoch [22/100], Loss: 0.8880\n",
      "Validation Accuracy: 70.23%\n",
      "Epoch [23/100], Loss: 0.8835\n",
      "Validation Accuracy: 70.46%\n",
      "Epoch [24/100], Loss: 0.8821\n",
      "Validation Accuracy: 70.16%\n",
      "Epoch [25/100], Loss: 0.8799\n",
      "Validation Accuracy: 70.05%\n",
      "Epoch [26/100], Loss: 0.8756\n",
      "Validation Accuracy: 69.88%\n",
      "Epoch [27/100], Loss: 0.8748\n",
      "Validation Accuracy: 70.20%\n",
      "Epoch [28/100], Loss: 0.8716\n",
      "Validation Accuracy: 69.69%\n",
      "Epoch [29/100], Loss: 0.8677\n",
      "Validation Accuracy: 70.05%\n",
      "Epoch [30/100], Loss: 0.8660\n",
      "Validation Accuracy: 69.76%\n",
      "Epoch [31/100], Loss: 0.8644\n",
      "Validation Accuracy: 70.12%\n",
      "Epoch [32/100], Loss: 0.8654\n",
      "Validation Accuracy: 70.41%\n",
      "Epoch [33/100], Loss: 0.8598\n",
      "Validation Accuracy: 70.04%\n",
      "Epoch [34/100], Loss: 0.8595\n",
      "Validation Accuracy: 70.21%\n",
      "Epoch [35/100], Loss: 0.8568\n",
      "Validation Accuracy: 70.10%\n",
      "Epoch [36/100], Loss: 0.8543\n",
      "Validation Accuracy: 70.12%\n",
      "Epoch [37/100], Loss: 0.8545\n",
      "Validation Accuracy: 70.22%\n",
      "Epoch [38/100], Loss: 0.8508\n",
      "Validation Accuracy: 70.04%\n",
      "Epoch [39/100], Loss: 0.8488\n",
      "Validation Accuracy: 69.77%\n",
      "Epoch [40/100], Loss: 0.8490\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [41/100], Loss: 0.8459\n",
      "Validation Accuracy: 70.13%\n",
      "Epoch [42/100], Loss: 0.8464\n",
      "Validation Accuracy: 70.03%\n",
      "Epoch [43/100], Loss: 0.8448\n",
      "Validation Accuracy: 70.05%\n",
      "Epoch [44/100], Loss: 0.8419\n",
      "Validation Accuracy: 70.04%\n",
      "Epoch [45/100], Loss: 0.8419\n",
      "Validation Accuracy: 69.75%\n",
      "Epoch [46/100], Loss: 0.8406\n",
      "Validation Accuracy: 70.30%\n",
      "Epoch [47/100], Loss: 0.8385\n",
      "Validation Accuracy: 70.11%\n",
      "Epoch [48/100], Loss: 0.8390\n",
      "Validation Accuracy: 69.87%\n",
      "Epoch [49/100], Loss: 0.8365\n",
      "Validation Accuracy: 70.10%\n",
      "Epoch [50/100], Loss: 0.8370\n",
      "Validation Accuracy: 70.10%\n",
      "Epoch [51/100], Loss: 0.8346\n",
      "Validation Accuracy: 70.24%\n",
      "Epoch [52/100], Loss: 0.8348\n",
      "Validation Accuracy: 70.19%\n",
      "Epoch [53/100], Loss: 0.8339\n",
      "Validation Accuracy: 70.24%\n",
      "Epoch [54/100], Loss: 0.8292\n",
      "Validation Accuracy: 70.12%\n",
      "Epoch [55/100], Loss: 0.8289\n",
      "Validation Accuracy: 70.08%\n",
      "Epoch [56/100], Loss: 0.8294\n",
      "Validation Accuracy: 69.93%\n",
      "Epoch [57/100], Loss: 0.8268\n",
      "Validation Accuracy: 70.09%\n",
      "Epoch [58/100], Loss: 0.8275\n",
      "Validation Accuracy: 70.05%\n",
      "Epoch [59/100], Loss: 0.8261\n",
      "Validation Accuracy: 70.05%\n",
      "Epoch [60/100], Loss: 0.8267\n",
      "Validation Accuracy: 70.22%\n",
      "Epoch [61/100], Loss: 0.8234\n",
      "Validation Accuracy: 70.12%\n",
      "Epoch [62/100], Loss: 0.8253\n",
      "Validation Accuracy: 69.99%\n",
      "Epoch [63/100], Loss: 0.8216\n",
      "Validation Accuracy: 70.35%\n",
      "Epoch [64/100], Loss: 0.8224\n",
      "Validation Accuracy: 70.04%\n",
      "Epoch [65/100], Loss: 0.8218\n",
      "Validation Accuracy: 70.22%\n",
      "Epoch [66/100], Loss: 0.8212\n",
      "Validation Accuracy: 70.20%\n",
      "Epoch [67/100], Loss: 0.8207\n",
      "Validation Accuracy: 70.18%\n",
      "Epoch [68/100], Loss: 0.8209\n",
      "Validation Accuracy: 70.00%\n",
      "Epoch [69/100], Loss: 0.8192\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [70/100], Loss: 0.8173\n",
      "Validation Accuracy: 69.92%\n",
      "Epoch [71/100], Loss: 0.8181\n",
      "Validation Accuracy: 70.18%\n",
      "Epoch [72/100], Loss: 0.8176\n",
      "Validation Accuracy: 70.16%\n",
      "Epoch [73/100], Loss: 0.8171\n",
      "Validation Accuracy: 70.20%\n",
      "Epoch [74/100], Loss: 0.8173\n",
      "Validation Accuracy: 69.87%\n",
      "Epoch [75/100], Loss: 0.8151\n",
      "Validation Accuracy: 70.16%\n",
      "Epoch [76/100], Loss: 0.8143\n",
      "Validation Accuracy: 70.33%\n",
      "Epoch [77/100], Loss: 0.8127\n",
      "Validation Accuracy: 70.36%\n",
      "Epoch [78/100], Loss: 0.8141\n",
      "Validation Accuracy: 70.23%\n",
      "Epoch [79/100], Loss: 0.8134\n",
      "Validation Accuracy: 70.10%\n",
      "Epoch [80/100], Loss: 0.8114\n",
      "Validation Accuracy: 69.96%\n",
      "Epoch [81/100], Loss: 0.8112\n",
      "Validation Accuracy: 70.18%\n",
      "Epoch [82/100], Loss: 0.8098\n",
      "Validation Accuracy: 69.93%\n",
      "Epoch [83/100], Loss: 0.8115\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [84/100], Loss: 0.8091\n",
      "Validation Accuracy: 70.03%\n",
      "Epoch [85/100], Loss: 0.8103\n",
      "Validation Accuracy: 69.86%\n",
      "Epoch [86/100], Loss: 0.8103\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [87/100], Loss: 0.8085\n",
      "Validation Accuracy: 69.80%\n",
      "Epoch [88/100], Loss: 0.8077\n",
      "Validation Accuracy: 70.14%\n",
      "Epoch [89/100], Loss: 0.8056\n",
      "Validation Accuracy: 69.88%\n",
      "Epoch [90/100], Loss: 0.8089\n",
      "Validation Accuracy: 69.78%\n",
      "Epoch [91/100], Loss: 0.8067\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [92/100], Loss: 0.8048\n",
      "Validation Accuracy: 69.71%\n",
      "Epoch [93/100], Loss: 0.8067\n",
      "Validation Accuracy: 69.96%\n",
      "Epoch [94/100], Loss: 0.8055\n",
      "Validation Accuracy: 69.89%\n",
      "Epoch [95/100], Loss: 0.8056\n",
      "Validation Accuracy: 70.00%\n",
      "Epoch [96/100], Loss: 0.8046\n",
      "Validation Accuracy: 70.15%\n",
      "Epoch [97/100], Loss: 0.8036\n",
      "Validation Accuracy: 69.81%\n",
      "Epoch [98/100], Loss: 0.8049\n",
      "Validation Accuracy: 69.97%\n",
      "Epoch [99/100], Loss: 0.8030\n",
      "Validation Accuracy: 69.88%\n",
      "Epoch [100/100], Loss: 0.8030\n",
      "Validation Accuracy: 69.97%\n",
      "Test Accuracy: 69.99%\n",
      "Model, encoder, and metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_final.shape[1]\n",
    "output_size = len(np.unique(y_encoded))\n",
    "model = NeuralNetworkWithPrecomputedBERT(input_size, output_size)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*100)\n",
    "\n",
    "# Training loop with Early Stopping\n",
    "epochs = 100\n",
    "best_val_accuracy = 0\n",
    "patience = 10  # Early stopping patience\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Validation metrics\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_accuracy = accuracy_score(y_val, val_predicted)\n",
    "        print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# Test metrics\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = accuracy_score(y_test, test_predicted)\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the encoder and metadata\n",
    "torch.save(model.state_dict(), f'{output_dir}/advanced_trained_model_2.pth')\n",
    "torch.save(model, f'{output_dir}/advanced_trained_model_2_1.pth')\n",
    "joblib.dump(encoder, f'{output_dir}/advanced_trained_encoder_2.pkl')\n",
    "joblib.dump({'input_size': input_size, 'output_size': output_size}, f'{output_dir}/advanced_metadata_2.pkl')\n",
    "print(\"Model, encoder, and metadata saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T22:26:12.313732Z",
     "iopub.status.busy": "2025-03-12T22:26:12.313317Z",
     "iopub.status.idle": "2025-03-12T22:28:29.235801Z",
     "shell.execute_reply": "2025-03-12T22:28:29.234903Z",
     "shell.execute_reply.started": "2025-03-12T22:26:12.313701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.2504, Training Accuracy: 80.87%\n",
      "Validation Accuracy: 83.01%\n",
      "Epoch [2/100], Loss: 1.0442, Training Accuracy: 82.99%\n",
      "Validation Accuracy: 83.81%\n",
      "Epoch [3/100], Loss: 1.0070, Training Accuracy: 83.62%\n",
      "Validation Accuracy: 83.95%\n",
      "Epoch [4/100], Loss: 0.9863, Training Accuracy: 84.15%\n",
      "Validation Accuracy: 83.57%\n",
      "Epoch [5/100], Loss: 0.9722, Training Accuracy: 84.24%\n",
      "Validation Accuracy: 84.39%\n",
      "Epoch [6/100], Loss: 0.9619, Training Accuracy: 84.56%\n",
      "Validation Accuracy: 84.40%\n",
      "Epoch [7/100], Loss: 0.9510, Training Accuracy: 84.74%\n",
      "Validation Accuracy: 84.69%\n",
      "Epoch [8/100], Loss: 0.9431, Training Accuracy: 84.88%\n",
      "Validation Accuracy: 84.78%\n",
      "Epoch [9/100], Loss: 0.9352, Training Accuracy: 84.96%\n",
      "Validation Accuracy: 85.03%\n",
      "Epoch [10/100], Loss: 0.9302, Training Accuracy: 85.18%\n",
      "Validation Accuracy: 84.90%\n",
      "Epoch [11/100], Loss: 0.9258, Training Accuracy: 85.33%\n",
      "Validation Accuracy: 84.80%\n",
      "Epoch [12/100], Loss: 0.9172, Training Accuracy: 85.35%\n",
      "Validation Accuracy: 84.76%\n",
      "Epoch [13/100], Loss: 0.9138, Training Accuracy: 85.49%\n",
      "Validation Accuracy: 84.84%\n",
      "Epoch [14/100], Loss: 0.9064, Training Accuracy: 85.61%\n",
      "Validation Accuracy: 84.95%\n",
      "Epoch [15/100], Loss: 0.9025, Training Accuracy: 85.81%\n",
      "Validation Accuracy: 85.03%\n",
      "Epoch [16/100], Loss: 0.8998, Training Accuracy: 85.75%\n",
      "Validation Accuracy: 84.72%\n",
      "Epoch [17/100], Loss: 0.8961, Training Accuracy: 85.93%\n",
      "Validation Accuracy: 85.01%\n",
      "Epoch [18/100], Loss: 0.8917, Training Accuracy: 85.93%\n",
      "Validation Accuracy: 85.16%\n",
      "Epoch [19/100], Loss: 0.8876, Training Accuracy: 86.07%\n",
      "Validation Accuracy: 85.09%\n",
      "Epoch [20/100], Loss: 0.8865, Training Accuracy: 86.08%\n",
      "Validation Accuracy: 85.27%\n",
      "Epoch [21/100], Loss: 0.8804, Training Accuracy: 86.22%\n",
      "Validation Accuracy: 85.10%\n",
      "Epoch [22/100], Loss: 0.8773, Training Accuracy: 86.14%\n",
      "Validation Accuracy: 85.31%\n",
      "Epoch [23/100], Loss: 0.8756, Training Accuracy: 86.29%\n",
      "Validation Accuracy: 85.01%\n",
      "Epoch [24/100], Loss: 0.8726, Training Accuracy: 86.32%\n",
      "Validation Accuracy: 85.20%\n",
      "Epoch [25/100], Loss: 0.8700, Training Accuracy: 86.37%\n",
      "Validation Accuracy: 85.33%\n",
      "Epoch [26/100], Loss: 0.8651, Training Accuracy: 86.49%\n",
      "Validation Accuracy: 85.53%\n",
      "Epoch [27/100], Loss: 0.8632, Training Accuracy: 86.56%\n",
      "Validation Accuracy: 85.01%\n",
      "Epoch [28/100], Loss: 0.8615, Training Accuracy: 86.68%\n",
      "Validation Accuracy: 84.86%\n",
      "Epoch [29/100], Loss: 0.8577, Training Accuracy: 86.69%\n",
      "Validation Accuracy: 85.14%\n",
      "Epoch [30/100], Loss: 0.8551, Training Accuracy: 86.73%\n",
      "Validation Accuracy: 85.01%\n",
      "Epoch [31/100], Loss: 0.8539, Training Accuracy: 86.70%\n",
      "Validation Accuracy: 85.15%\n",
      "Epoch [32/100], Loss: 0.8516, Training Accuracy: 86.79%\n",
      "Validation Accuracy: 85.31%\n",
      "Epoch [33/100], Loss: 0.8488, Training Accuracy: 86.84%\n",
      "Validation Accuracy: 85.29%\n",
      "Epoch [34/100], Loss: 0.8485, Training Accuracy: 87.00%\n",
      "Validation Accuracy: 85.16%\n",
      "Epoch [35/100], Loss: 0.8459, Training Accuracy: 86.88%\n",
      "Validation Accuracy: 85.22%\n",
      "Epoch [36/100], Loss: 0.8419, Training Accuracy: 87.05%\n",
      "Validation Accuracy: 84.97%\n",
      "Early stopping due to no improvement in validation accuracy.\n",
      "Test Accuracy: 85.07%\n",
      "Model, encoder, and metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_final.shape[1]\n",
    "output_size = len(np.unique(y_encoded))\n",
    "model = NeuralNetworkWithPrecomputedBERT(input_size, output_size)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*100)\n",
    "\n",
    "# Training loop with Early Stopping and Training Accuracy\n",
    "epochs = 100\n",
    "best_val_accuracy = 0\n",
    "patience = 10  # Early stopping patience\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += batch_y.size(0)\n",
    "        correct_train += (predicted == batch_y).sum().item()\n",
    "\n",
    "    # Calculate training accuracy for the epoch\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}, Training Accuracy: {((train_accuracy * 100)):.2f}%')\n",
    "\n",
    "    # Validation metrics\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_accuracy = accuracy_score(y_val, val_predicted)\n",
    "        print(f'Validation Accuracy: {((val_accuracy * 100)):.2f}%')\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), f'{output_dir}/best_trained_model_final_{timestamp}.pth')\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping due to no improvement in validation accuracy.\")\n",
    "                break\n",
    "\n",
    "# Test metrics\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_accuracy = accuracy_score(y_test, test_predicted)\n",
    "    print(f'Test Accuracy: {((test_accuracy * 100)):.2f}%')\n",
    "\n",
    "# Save the encoder and metadata\n",
    "torch.save(model.state_dict(), f'{output_dir}/advanced_trained_model_final.pth')\n",
    "torch.save(model, f'{output_dir}/advanced_trained_model_2_final.pth')\n",
    "joblib.dump(encoder, f'{output_dir}/advanced_trained_encoder_final.pkl')\n",
    "joblib.dump({'input_size': input_size, 'output_size': output_size}, f'{output_dir}/advanced_metadata_final.pkl')\n",
    "print(\"Model, encoder, and metadata saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6802056,
     "sourceId": 10937984,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
